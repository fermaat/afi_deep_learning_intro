{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "\n",
    "On this notebook we will take a look at some of the different activation functions present in keras backend and will compare them.\n",
    "\n",
    "## The data\n",
    "We will use our old friend MNIST for its simplicity. \n",
    "\n",
    "<font color=red><b>Load the dataset and preprocess it. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session() \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Architecture\n",
    "Let's build a very simple model on this example. It will consist on:\n",
    "- A dense layer with 512 units, relu activated\n",
    "- A dense layer with the number of classes as  the amount of units, softmax activated\n",
    "- Use RMSprop as the optimizer and categorical crossentropy as the loss function. Add accuracy to the metrics\n",
    "\n",
    "<font color=red><b> Build the model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b> Train the model for 5 epochs and with a batch size of 128. Use the test data as validation and evaluate the model. Keep the information in a history variable\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2519 - accuracy: 0.9278 - val_loss: 0.1242 - val_accuracy: 0.9628\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1030 - accuracy: 0.9696 - val_loss: 0.0868 - val_accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0674 - accuracy: 0.9801 - val_loss: 0.0766 - val_accuracy: 0.9772\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.0646 - val_accuracy: 0.9807\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0679 - val_accuracy: 0.9781\n",
      "Test loss: 0.068\n",
      "Test accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "    \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=100)\n",
    "\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the loss for both using matplotlib. Is it nice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff85079c128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build networks using all activations\n",
    "Now let's run the model with all the activations in the list and view the results in tensorboard\n",
    "\n",
    "\n",
    "<font color=red><b> Let's do precisely that!\n",
    "    <br> Hint: remember to add the tensorboard as a callback for the training.\n",
    "    <br> Hint2: use the function os.path.join to include the activation name on each model call\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3829 - accuracy: 0.8892 - val_loss: 0.3109 - val_accuracy: 0.9133\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.3096 - accuracy: 0.9135 - val_loss: 0.3138 - val_accuracy: 0.9119\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2955 - accuracy: 0.9178 - val_loss: 0.3409 - val_accuracy: 0.9092\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2873 - accuracy: 0.9209 - val_loss: 0.2985 - val_accuracy: 0.9198\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2843 - accuracy: 0.9200 - val_loss: 0.2848 - val_accuracy: 0.9216\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2787 - accuracy: 0.9218 - val_loss: 0.2889 - val_accuracy: 0.9201\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2746 - accuracy: 0.9241 - val_loss: 0.2818 - val_accuracy: 0.9215\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2728 - accuracy: 0.9239 - val_loss: 0.2818 - val_accuracy: 0.9216\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2715 - accuracy: 0.9245 - val_loss: 0.2880 - val_accuracy: 0.9207\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2689 - accuracy: 0.9256 - val_loss: 0.2826 - val_accuracy: 0.9217\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2673 - accuracy: 0.9253 - val_loss: 0.2851 - val_accuracy: 0.9209\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2658 - accuracy: 0.9259 - val_loss: 0.2822 - val_accuracy: 0.9251\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2649 - accuracy: 0.9263 - val_loss: 0.2884 - val_accuracy: 0.9232\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2631 - accuracy: 0.9270 - val_loss: 0.3032 - val_accuracy: 0.9152\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2625 - accuracy: 0.9274 - val_loss: 0.2940 - val_accuracy: 0.9233\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2613 - accuracy: 0.9274 - val_loss: 0.2877 - val_accuracy: 0.9205\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2597 - accuracy: 0.9281 - val_loss: 0.2846 - val_accuracy: 0.9236\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2586 - accuracy: 0.9278 - val_loss: 0.2905 - val_accuracy: 0.9216\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.2586 - accuracy: 0.9283 - val_loss: 0.2970 - val_accuracy: 0.9214\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2576 - accuracy: 0.9286 - val_loss: 0.2925 - val_accuracy: 0.9217\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.4269 - accuracy: 0.8853 - val_loss: 0.2551 - val_accuracy: 0.9265\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2340 - accuracy: 0.9319 - val_loss: 0.1964 - val_accuracy: 0.9429\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1770 - accuracy: 0.9484 - val_loss: 0.1593 - val_accuracy: 0.9532\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1391 - accuracy: 0.9596 - val_loss: 0.1300 - val_accuracy: 0.9607\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1131 - accuracy: 0.9663 - val_loss: 0.1120 - val_accuracy: 0.9659\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0933 - accuracy: 0.9730 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0790 - accuracy: 0.9769 - val_loss: 0.0974 - val_accuracy: 0.9703\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.0805 - val_accuracy: 0.9753\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0589 - accuracy: 0.9828 - val_loss: 0.0787 - val_accuracy: 0.9764\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0511 - accuracy: 0.9850 - val_loss: 0.0747 - val_accuracy: 0.9775\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0447 - accuracy: 0.9873 - val_loss: 0.0695 - val_accuracy: 0.9779\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0388 - accuracy: 0.9891 - val_loss: 0.0727 - val_accuracy: 0.9785\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0341 - accuracy: 0.9904 - val_loss: 0.0731 - val_accuracy: 0.9782\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.0658 - val_accuracy: 0.9809\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0662 - val_accuracy: 0.9796\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0635 - val_accuracy: 0.9799\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0197 - accuracy: 0.9952 - val_loss: 0.0658 - val_accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0172 - accuracy: 0.9961 - val_loss: 0.0676 - val_accuracy: 0.9798\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.0719 - val_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.0663 - val_accuracy: 0.9811\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.3369 - accuracy: 0.9010 - val_loss: 0.2072 - val_accuracy: 0.9385\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1750 - accuracy: 0.9493 - val_loss: 0.1463 - val_accuracy: 0.9559\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.1172 - accuracy: 0.9644 - val_loss: 0.1061 - val_accuracy: 0.9684\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0850 - accuracy: 0.9752 - val_loss: 0.1018 - val_accuracy: 0.9678\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0654 - accuracy: 0.9809 - val_loss: 0.0784 - val_accuracy: 0.9762\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0507 - accuracy: 0.9849 - val_loss: 0.0766 - val_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0403 - accuracy: 0.9881 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0256 - accuracy: 0.9927 - val_loss: 0.0663 - val_accuracy: 0.9794\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.0662 - val_accuracy: 0.9802\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0685 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0636 - val_accuracy: 0.9816\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0678 - val_accuracy: 0.9802\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0680 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0625 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0666 - val_accuracy: 0.9828\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0633 - val_accuracy: 0.9838\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0728 - val_accuracy: 0.9813\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0934 - val_accuracy: 0.9762\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0723 - val_accuracy: 0.9830\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2555 - accuracy: 0.9248 - val_loss: 0.1451 - val_accuracy: 0.9553\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.1032 - accuracy: 0.9688 - val_loss: 0.0888 - val_accuracy: 0.9727\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0678 - accuracy: 0.9801 - val_loss: 0.0787 - val_accuracy: 0.9763\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0771 - val_accuracy: 0.9761\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0370 - accuracy: 0.9891 - val_loss: 0.0705 - val_accuracy: 0.9785\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0689 - val_accuracy: 0.9793\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.0611 - val_accuracy: 0.9825\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0678 - val_accuracy: 0.9792\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0695 - val_accuracy: 0.9801\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0730 - val_accuracy: 0.9814\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0735 - val_accuracy: 0.9808\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0779 - val_accuracy: 0.9812\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0802 - val_accuracy: 0.9814\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0930 - val_accuracy: 0.9797\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0855 - val_accuracy: 0.9813\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0913 - val_accuracy: 0.9805\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0917 - val_accuracy: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0983 - val_accuracy: 0.9822\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1002 - val_accuracy: 0.9810\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 8.9458e-04 - accuracy: 0.9998 - val_loss: 0.1064 - val_accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "epochs = 20\n",
    "log_path = '/home/fer/data/formaciones/afi/tensorboard_log/activations_experiment'\n",
    "for activation in [None, 'sigmoid', 'tanh', 'relu']:\n",
    "    # build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(784,)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    tensorboard = TensorBoard(os.path.join(log_path,f'{activation}_{time.time()}'))\n",
    "    # fit the model, adding the tensorboard to the callbacks\n",
    "    model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_tf2",
   "language": "python",
   "name": "dl_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
