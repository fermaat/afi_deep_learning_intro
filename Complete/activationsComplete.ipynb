{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions\n",
    "\n",
    "On this notebook we will take a look at some of the different activation functions present in keras backend and will compare them.\n",
    "\n",
    "## The data\n",
    "We will use our old friend MNIST for its simplicity. \n",
    "\n",
    "<font color=red><b>Load the dataset and preprocess it. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import tensorflow as tf\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session() \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Architecture\n",
    "Let's build a very simple model on this example. It will consist on:\n",
    "- A dense layer with 512 units, relu activated\n",
    "- A dense layer with the number of classes as  the amount of units, softmax activated\n",
    "- Use RMSprop as the optimizer and categorical crossentropy as the loss function. Add accuracy to the metrics\n",
    "\n",
    "<font color=red><b> Build the model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b> Train the model for 5 epochs and with a batch size of 128. Use the test data as validation and evaluate the model. Keep the information in a history variable\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.2555 - accuracy: 0.9268 - val_loss: 0.1262 - val_accuracy: 0.9612\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1050 - accuracy: 0.9680 - val_loss: 0.0929 - val_accuracy: 0.9710\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0684 - accuracy: 0.9793 - val_loss: 0.0747 - val_accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0501 - accuracy: 0.9848 - val_loss: 0.0661 - val_accuracy: 0.9803\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0667 - val_accuracy: 0.9790\n",
      "Test loss: 0.067\n",
      "Test accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "    \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=100)\n",
    "\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the loss for both using matplotlib. Is it nice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f93f0510f60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build networks using all activations\n",
    "Now let's run the model with all the activations in the list and view the results in tensorboard\n",
    "\n",
    "\n",
    "<font color=red><b> Let's do precisely that!\n",
    "    <br> Hint: remember to add the tensorboard as a callback for the training.\n",
    "    <br> Hint2: use the function os.path.join to include the activation name on each model call\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3829 - accuracy: 0.8866 - val_loss: 0.3203 - val_accuracy: 0.9056\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3094 - accuracy: 0.9136 - val_loss: 0.3023 - val_accuracy: 0.9161\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2959 - accuracy: 0.9173 - val_loss: 0.3059 - val_accuracy: 0.9137\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2874 - accuracy: 0.9201 - val_loss: 0.2831 - val_accuracy: 0.9246\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2829 - accuracy: 0.9214 - val_loss: 0.3154 - val_accuracy: 0.9123\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2835 - val_accuracy: 0.9207\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2756 - accuracy: 0.9223 - val_loss: 0.2880 - val_accuracy: 0.9204\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2734 - accuracy: 0.9245 - val_loss: 0.2928 - val_accuracy: 0.9202\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2710 - accuracy: 0.9259 - val_loss: 0.2921 - val_accuracy: 0.9232\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2686 - accuracy: 0.9251 - val_loss: 0.2876 - val_accuracy: 0.9227\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2672 - accuracy: 0.9254 - val_loss: 0.2856 - val_accuracy: 0.9242\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2648 - accuracy: 0.9263 - val_loss: 0.2914 - val_accuracy: 0.9236\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2652 - accuracy: 0.9251 - val_loss: 0.2862 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2626 - accuracy: 0.9273 - val_loss: 0.2949 - val_accuracy: 0.9214\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2619 - accuracy: 0.9269 - val_loss: 0.2873 - val_accuracy: 0.9216\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2605 - accuracy: 0.9274 - val_loss: 0.2795 - val_accuracy: 0.9240\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2601 - accuracy: 0.9284 - val_loss: 0.2887 - val_accuracy: 0.9210\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2585 - accuracy: 0.9281 - val_loss: 0.2920 - val_accuracy: 0.9213\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2594 - accuracy: 0.9285 - val_loss: 0.2871 - val_accuracy: 0.9232\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2566 - accuracy: 0.9289 - val_loss: 0.2844 - val_accuracy: 0.9254\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.4218 - accuracy: 0.8852 - val_loss: 0.2587 - val_accuracy: 0.9237\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2352 - accuracy: 0.9313 - val_loss: 0.1974 - val_accuracy: 0.9414\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1777 - accuracy: 0.9483 - val_loss: 0.1528 - val_accuracy: 0.9540\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.1386 - accuracy: 0.9597 - val_loss: 0.1280 - val_accuracy: 0.9620\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.1122 - accuracy: 0.9670 - val_loss: 0.1128 - val_accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0930 - accuracy: 0.9733 - val_loss: 0.1011 - val_accuracy: 0.9682\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0781 - accuracy: 0.9774 - val_loss: 0.0912 - val_accuracy: 0.9710\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0668 - accuracy: 0.9805 - val_loss: 0.0865 - val_accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0569 - accuracy: 0.9833 - val_loss: 0.0778 - val_accuracy: 0.9766\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.0718 - val_accuracy: 0.9783\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0430 - accuracy: 0.9873 - val_loss: 0.0706 - val_accuracy: 0.9775\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0683 - val_accuracy: 0.9799\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.0673 - val_accuracy: 0.9796\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0288 - accuracy: 0.9919 - val_loss: 0.0634 - val_accuracy: 0.9813\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.0249 - accuracy: 0.9935 - val_loss: 0.0619 - val_accuracy: 0.9808\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.0622 - val_accuracy: 0.9816\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.0627 - val_accuracy: 0.9818\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.0647 - val_accuracy: 0.9810\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0143 - accuracy: 0.9968 - val_loss: 0.0659 - val_accuracy: 0.9810\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0653 - val_accuracy: 0.9805\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3361 - accuracy: 0.9004 - val_loss: 0.2378 - val_accuracy: 0.9290\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.1752 - accuracy: 0.9488 - val_loss: 0.1313 - val_accuracy: 0.9614\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.1164 - accuracy: 0.9655 - val_loss: 0.1088 - val_accuracy: 0.9682\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0853 - accuracy: 0.9745 - val_loss: 0.0857 - val_accuracy: 0.9739\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0655 - accuracy: 0.9807 - val_loss: 0.0791 - val_accuracy: 0.9764\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0710 - val_accuracy: 0.9787\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.0731 - val_accuracy: 0.9780\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0317 - accuracy: 0.9904 - val_loss: 0.0689 - val_accuracy: 0.9789\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0251 - accuracy: 0.9930 - val_loss: 0.0670 - val_accuracy: 0.9780\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0612 - val_accuracy: 0.9817\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.0638 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0608 - val_accuracy: 0.9828\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0677 - val_accuracy: 0.9805\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0642 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0740 - val_accuracy: 0.9811\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0630 - val_accuracy: 0.9824\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0692 - val_accuracy: 0.9821\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0728 - val_accuracy: 0.9814\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0734 - val_accuracy: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0699 - val_accuracy: 0.9831\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2550 - accuracy: 0.9263 - val_loss: 0.1285 - val_accuracy: 0.9611\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1029 - accuracy: 0.9694 - val_loss: 0.1011 - val_accuracy: 0.9692\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0678 - accuracy: 0.9798 - val_loss: 0.0817 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9824\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0685 - val_accuracy: 0.9784\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0697 - val_accuracy: 0.9792\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0689 - val_accuracy: 0.9813\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0667 - val_accuracy: 0.9819\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0766 - val_accuracy: 0.9809\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0740 - val_accuracy: 0.9813\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0775 - val_accuracy: 0.9820\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0820 - val_accuracy: 0.9809\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0847 - val_accuracy: 0.9818\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0839 - val_accuracy: 0.9813\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0833 - val_accuracy: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0997 - val_accuracy: 0.9790\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0918 - val_accuracy: 0.9815\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0962 - val_accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "epochs = 20\n",
    "log_path = '/home/fer/data/formaciones/afi/tensorboard_log/activations_experiment2'\n",
    "for activation in [None, 'sigmoid', 'tanh', 'relu']:\n",
    "    # build and compile the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(784,)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    tensorboard = TensorBoard(os.path.join(log_path,f'{activation}_{time.time()}'))\n",
    "    # fit the model, adding the tensorboard to the callbacks\n",
    "    model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_tf2",
   "language": "python",
   "name": "dl_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
