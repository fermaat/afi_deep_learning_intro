{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard model stats\n",
    "On this notebook we are going to train some models on the same dataset and compare their performances using the tensorboard visualization tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from time import time\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The dataset is composed by 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. These are the image classes:\n",
    "- airplane \n",
    "- automobile \n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of classes\n",
    "num_classes = 10\n",
    "\n",
    "# Split the data into train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Plot some examples of the dataset.\n",
    "<br>Hint: use the imshow function of the pyplot package</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "for j in range (10):\n",
    "    ...\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Preprocess the data: both the images and the targets\n",
    "<br>Hint: use the to_categorical function from keras.utils. Use squeeze to remove unidimensional data from the targets</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "x_train = ...\n",
    "x_test = ...\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train_cat = ...\n",
    "y_test_cat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Let's build a model and train it on the dataset. Our model will consist on:\n",
    "- A convolutional layer with 32 filters 3x3, padding= same  and relu activated (don't panic, we will learn a lot about them with Daniel)\n",
    "- A 2x2 maxpool layer (idem)\n",
    "- 0.25 dropout layer\n",
    "- A flatten layer, followed by a dense 512, relu activated\n",
    "- 0.5 dropout layer\n",
    "- the final dense, softmax activated layer.\n",
    "- Add adam as th eoptimizer and categorical crossentropy as the loss. Include accuracy on the compiler\n",
    "\n",
    "\n",
    "<font color=red><b>Create the model and compile it\n",
    "<br>Hint: use the imported functions </b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Create a TensorBoard instance with the path to the logs directory. Include it as a callback on the fit function. Fit the model with the validation data for 25 epochs\n",
    "<br>Hint: use the positional format with the time for the log_dir </b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorBoard instance with the path to the logs directory\n",
    "tensorboard = ...\n",
    "\n",
    "#Train the model using tensorboard instance in the callbacks\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_base",
   "language": "python",
   "name": "dl_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
