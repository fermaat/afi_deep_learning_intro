{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10 Neural Nets vs classic algorithms\n",
    "\n",
    "On this notebook we are going to compare neural networks performanc against the classic algorithms on the same task.\n",
    "\n",
    "## The dataset:\n",
    "As we mentoioned, we are going to use the CIFAR10 data. Let's take a look:\n",
    "\n",
    "The dataset is composed by 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. These are the image classes:\n",
    "- airplane \n",
    "- automobile \n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3072)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "num_classes = 10\n",
    "# The data, split between train and test sets:\n",
    "(trainX, y_train), (testX, y_test) = cifar10.load_data()\n",
    "x_train = trainX.reshape(trainX.shape[0],-1)\n",
    "x_test = testX.reshape(testX.shape[0], -1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Plot some examples of the dataset.\n",
    "<br>Hint: use the imshow function of the pyplot package</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic approach\n",
    "One of the main takeouts from DL is that it extract features from the data. We are facing images. So, let's reduce the disadvantage of the classic algorithms and first, let's get some interesting features. We will do a feature extraction using pca, and then will test against some algorithms like random forest, svm, knn or logistic regression\n",
    "\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>Perform the PCA fitting to the data and extract the optimal number of components to explain at least 95% of the variance explained\n",
    "<br>Hint: find the appropiated attribute on the pca</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b> Now create the pca with the given number of components. Fit the training and transform the testing data.\n",
    "<br>Hint: Use whiten=True</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying PCA with k calcuated above\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>  Train and evaluate the random forest\n",
    "<br>Hint: What data are you using?</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "...\n",
    "random_forest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>  Train and evaluate the knn\n",
    "<br>Hint: What data are you using?</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "...\n",
    "knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>  Train and evaluate the logistic regression\n",
    "<br>Hint: What data are you using?</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "...\n",
    "logistic_regression_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red><b>  Train and evaluate the svm\n",
    "<br>Hint: What data are you using?</b>\n",
    "    <br>Hint: Don't do it. It takes forever.</b>\n",
    "    <br>Hint: Really, please don't. It doesn't improve that much.</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "## Training\n",
    "svc = svm.SVC()\n",
    "...\n",
    "svc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier :  0.0048\n",
      "K Nearest Neighbors :  0.106\n",
      "Logistic Regression :  0.402\n",
      "Support Vector Classifier :  0.4838\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier : \", random_forest_score)\n",
    "print(\"K Nearest Neighbors : \", knn_score)\n",
    "print(\"Logistic Regression : \", logistic_regression_score)\n",
    "# print(\"Support Vector Classifier : \", svc_score) # 0.4838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural nets\n",
    "Will a neural net be able to improve those results? Let's see.\n",
    "\n",
    "<font color=red><b> Build the architecture you like for the neural network. Is it better or worse?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_base",
   "language": "python",
   "name": "dl_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
