{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard strikes again\n",
    "\n",
    "On this notebook we will see how pytorch handles tensorboard. It is not going to be a practice notebook, but a guided one. In fact, it has been extracted from pytorch tutorials, with a small change on the embeddings to visualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def almost_forward(self, x):\n",
    "        \"\"\"\n",
    "        This function has been created to be able to extract just the \n",
    "        features from the last layer. It could also be from the main forward function. \n",
    "        A nice exercise would be to build it from there.\n",
    "        \"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the writer from tensorboard. on each iteration you want to add you will call the writer. after a writer has been initialised and aomething has been written, you can call tensorboard:\n",
    "\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/home/fer/data/formaciones/afi/tensorboard_log/pytorch_tensorboard_example_4\n",
    "```\n",
    "You will log everythong into this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('/home/fer/data/formaciones/afi/tensorboard_log/pytorch_tensorboard_example_4/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to TensorBoard\n",
    "\n",
    "Now let’s write an image to our TensorBoard - specifically, a grid - using make_grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the model using TensorBoard\n",
    "\n",
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking model training with TensorBoard\n",
    "\n",
    "In the previous example, we simply printed the model’s running loss every 2000 iterations. Now, we’ll instead log the running loss to TensorBoard, along with a view into the predictions the model is making via the plot_classes_preds function.\n",
    "\n",
    "Finally, let’s train the model using the same model training code from the prior tutorial, but writing results to TensorBoard every 1000 batches instead of printing to console; this is done using the add_scalar function.\n",
    "\n",
    "In addition, as we train, we’ll generate an image showing the model’s predictions vs. the actual results on the four images included in that batch.\n",
    "\n",
    "\n",
    "In addition, we can look at the predictions the model made on arbitrary batches throughout learning. See the “Images” tab and scroll down under the “predictions vs. actuals” visualization to see this; this shows us that, for example, after just 3000 training iterations, the model was already able to distinguish between visually distinct classes such as shirts, sneakers, and coats, though it isn’t as confident as it becomes later on in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a “Projector” to TensorBoard\n",
    "\n",
    "We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper function\n",
    "def select_n_random(data, labels, n=1000):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "features = net.almost_forward(images.unsqueeze(1)/255.0)\n",
    "writer.add_embedding(features,\n",
    "                     metadata=class_labels,\n",
    "                     label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing trained models with TensorBoard\n",
    "You will now see a “PR Curves” tab that contains the precision-recall curves for each class. Go ahead and poke around; you’ll see that on some classes the model has nearly 100% “area under the curve”, whereas on others this area is lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_tf2",
   "language": "python",
   "name": "dl_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
